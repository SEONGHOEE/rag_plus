{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a671d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0b0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_function = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "vector_store = Chroma(\n",
    "    embedding_function=embedding_function,\n",
    "    collection_name='real_estate_tax',\n",
    "    persist_directory='./real_estate_tax_collection'\n",
    ")\n",
    "\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec70521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o',\n",
    "                 temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 질문-응답 작업을 수행하는 어시스턴트입니다.\n",
    "아래에 제공된 검색된 컨텍스트를 사용하여 질문에 답변하세요.\n",
    "답을 모를 경우, 모른다고 말하세요.\n",
    "최대 두 문장으로, 간결하게 답변하세요.\n",
    "\n",
    "질문: {question}\n",
    "컨텍스트: {context}\n",
    "답변:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever,  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebeb4f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "questions = [\n",
    "    \"종합부동산세의 부과 목적은 무엇이며, 재산세와 어떤 점에서 다른가?\", \n",
    "    \"1세대 1주택자가 종합부동산세 과세대상에서 제외되거나 세액 공제를 받기 위한 요건은 무엇인가?\",\n",
    "    \"주택을 3채 이상 보유한 개인에게 적용되는 종합부동산세 세율 구조는 어떻게 되는가?\",\n",
    "]\n",
    "\n",
    "gt = [\n",
    "    \"종합부동산세는 고액 부동산 보유자에 대한 조세 형평성과 부동산 가격 안정을 목적으로 한다.\",\n",
    "    \"1세대 1주택자는 공시가격 요건과 연령 및 보유기간 요건을 충족하면 세액 공제를 받을 수 있다.\",\n",
    "    \"3주택 이상 보유한 개인에게는 누진적인 고율의 종합부동산세 세율이 적용된다.\"\n",
    "]\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for query in questions:\n",
    "    answers.append(rag_chain.invoke(query))\n",
    "    contexts.append(\n",
    "        [doc.page_content for doc in retriever.get_relevant_documents(query)]\n",
    "    )\n",
    "\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    'ground_truth': gt\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19f2c7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hq/rb1q4rn512qbbsyy87bd4g9c0000gn/T/ipykernel_4860/2919819784.py:2: DeprecationWarning: Importing faithfulness from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import faithfulness\n",
      "  from ragas.metrics import (\n",
      "/var/folders/hq/rb1q4rn512qbbsyy87bd4g9c0000gn/T/ipykernel_4860/2919819784.py:2: DeprecationWarning: Importing answer_relevancy from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import answer_relevancy\n",
      "  from ragas.metrics import (\n",
      "/var/folders/hq/rb1q4rn512qbbsyy87bd4g9c0000gn/T/ipykernel_4860/2919819784.py:2: DeprecationWarning: Importing context_precision from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_precision\n",
      "  from ragas.metrics import (\n",
      "/var/folders/hq/rb1q4rn512qbbsyy87bd4g9c0000gn/T/ipykernel_4860/2919819784.py:2: DeprecationWarning: Importing context_recall from 'ragas.metrics' is deprecated and will be removed in v1.0. Please use 'ragas.metrics.collections' instead. Example: from ragas.metrics.collections import context_recall\n",
      "  from ragas.metrics import (\n",
      "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating:   8%|▊         | 1/12 [00:05<00:56,  5.13s/it]LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "LLM returned 1 generations instead of requested 3. Proceeding with 1 generations.\n",
      "Evaluating: 100%|██████████| 12/12 [00:45<00:00,  3.80s/it]\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_precision,\n",
    "    context_recall\n",
    ")\n",
    "\n",
    "result = evaluate(\n",
    "    dataset,\n",
    "    metrics=[\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_precision,\n",
    "        context_recall\n",
    "    ],\n",
    "     llm=llm  \n",
    ")\n",
    "\n",
    "df = result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b869007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>retrieved_contexts</th>\n",
       "      <th>response</th>\n",
       "      <th>reference</th>\n",
       "      <th>faithfulness</th>\n",
       "      <th>answer_relevancy</th>\n",
       "      <th>context_precision</th>\n",
       "      <th>context_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>종합부동산세의 부과 목적은 무엇이며, 재산세와 어떤 점에서 다른가?</td>\n",
       "      <td>[종합부동산세법\\n[시행 2023. 4. 18] [법률 제19342호, 2023. ...</td>\n",
       "      <td>종합부동산세의 부과 목적은 고액의 부동산 보유자에게 세금을 부과하여 조세부담의 형평...</td>\n",
       "      <td>종합부동산세는 고액 부동산 보유자에 대한 조세 형평성과 부동산 가격 안정을 목적으로...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.848478</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1세대 1주택자가 종합부동산세 과세대상에서 제외되거나 세액 공제를 받기 위한 요건은...</td>\n",
       "      <td>[과세기준일 현재 만 60세 이상인 1세대 1주택자가 제8조제4항 각 호의 어느 하...</td>\n",
       "      <td>1세대 1주택자가 종합부동산세 과세대상에서 제외되거나 세액 공제를 받기 위해서는 과...</td>\n",
       "      <td>1세대 1주택자는 공시가격 요건과 연령 및 보유기간 요건을 충족하면 세액 공제를 받...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.849387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>주택을 3채 이상 보유한 개인에게 적용되는 종합부동산세 세율 구조는 어떻게 되는가?</td>\n",
       "      <td>[납세의무자가 2주택 이하를 소유한 경우\\n\\n| 과세표준              ...</td>\n",
       "      <td>주택을 3채 이상 보유한 개인의 종합부동산세 세율 구조는 다음과 같습니다: 과세표준...</td>\n",
       "      <td>3주택 이상 보유한 개인에게는 누진적인 고율의 종합부동산세 세율이 적용된다.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.861491</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0              종합부동산세의 부과 목적은 무엇이며, 재산세와 어떤 점에서 다른가?   \n",
       "1  1세대 1주택자가 종합부동산세 과세대상에서 제외되거나 세액 공제를 받기 위한 요건은...   \n",
       "2     주택을 3채 이상 보유한 개인에게 적용되는 종합부동산세 세율 구조는 어떻게 되는가?   \n",
       "\n",
       "                                  retrieved_contexts  \\\n",
       "0  [종합부동산세법\\n[시행 2023. 4. 18] [법률 제19342호, 2023. ...   \n",
       "1  [과세기준일 현재 만 60세 이상인 1세대 1주택자가 제8조제4항 각 호의 어느 하...   \n",
       "2  [납세의무자가 2주택 이하를 소유한 경우\\n\\n| 과세표준              ...   \n",
       "\n",
       "                                            response  \\\n",
       "0  종합부동산세의 부과 목적은 고액의 부동산 보유자에게 세금을 부과하여 조세부담의 형평...   \n",
       "1  1세대 1주택자가 종합부동산세 과세대상에서 제외되거나 세액 공제를 받기 위해서는 과...   \n",
       "2  주택을 3채 이상 보유한 개인의 종합부동산세 세율 구조는 다음과 같습니다: 과세표준...   \n",
       "\n",
       "                                           reference  faithfulness  \\\n",
       "0  종합부동산세는 고액 부동산 보유자에 대한 조세 형평성과 부동산 가격 안정을 목적으로...           0.6   \n",
       "1  1세대 1주택자는 공시가격 요건과 연령 및 보유기간 요건을 충족하면 세액 공제를 받...           0.2   \n",
       "2         3주택 이상 보유한 개인에게는 누진적인 고율의 종합부동산세 세율이 적용된다.           1.0   \n",
       "\n",
       "   answer_relevancy  context_precision  context_recall  \n",
       "0          0.848478           1.000000             1.0  \n",
       "1          0.849387           1.000000             1.0  \n",
       "2          0.861491           0.833333             1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas\n",
      "  Downloading ragas-0.4.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.21.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (1.26.4)\n",
      "Requirement already satisfied: datasets>=4.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (4.5.0)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (0.8.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (2.9.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (1.6.0)\n",
      "Collecting appdirs (from ragas)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting diskcache>=5.6.3 (from ragas)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: typer in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (0.15.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (13.9.4)\n",
      "Requirement already satisfied: openai>=1.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (1.58.1)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (4.67.1)\n",
      "Collecting instructor (from ragas)\n",
      "  Downloading instructor-1.14.5-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: pillow>=10.4.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (11.0.0)\n",
      "Collecting networkx (from ragas)\n",
      "  Using cached networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting scikit-network (from ragas)\n",
      "  Downloading scikit_network-0.33.5-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (0.3.13)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (0.3.28)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (0.3.13)\n",
      "Requirement already satisfied: langchain_openai in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from ragas) (0.2.14)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (3.16.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (2.32.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (0.27.2)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (0.27.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from datasets>=4.0.0->ragas) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (3.11.11)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=4.0.0->ragas) (4.7.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=4.0.0->ragas) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=4.0.0->ragas) (1.0.7)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=4.0.0->ragas) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=4.0.0->ragas) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=4.0.0->ragas) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=4.0.0->ragas) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=4.0.0->ragas) (1.18.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from openai>=1.0.0->ragas) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from openai>=1.0.0->ragas) (0.8.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from pydantic>=2.0.0->ragas) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from pydantic>=2.0.0->ragas) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=4.0.0->ragas) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=4.0.0->ragas) (2.3.0)\n",
      "Collecting docstring-parser<1.0,>=0.16 (from instructor->ragas)\n",
      "  Downloading docstring_parser-0.17.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from instructor->ragas) (3.1.5)\n",
      "Collecting openai>=1.0.0 (from ragas)\n",
      "  Downloading openai-2.16.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tenacity<10.0.0,>=8.2.3 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from instructor->ragas) (9.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.4->instructor->ragas) (3.0.2)\n",
      "Collecting jiter<0.12,>=0.6.1 (from instructor->ragas)\n",
      "  Downloading jiter-0.11.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from rich->ragas) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from rich->ragas) (2.18.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from typer->ragas) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from typer->ragas) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->ragas) (0.1.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain->ragas) (2.0.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain->ragas) (0.3.4)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain->ragas) (0.2.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain-core->ragas) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain->ragas) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain->ragas) (1.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain-community->ragas) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain-community->ragas) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from langchain-community->ragas) (2.7.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-1.1.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.1.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-1.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.1.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.1.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.1.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.0.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_openai-1.0.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "  Downloading langchain_openai-1.0.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core (from ragas)\n",
      "  Downloading langchain_core-0.3.83-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_core-0.3.82-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading langchain_core-0.3.81-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Using cached langchain_core-0.3.80-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-0.3.34-py3-none-any.whl.metadata (2.4 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-core (from ragas)\n",
      "  Downloading langchain_core-0.3.77-py3-none-any.whl.metadata (3.2 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting langchain_openai (from ragas)\n",
      "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.32-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.31-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.30-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.3.28-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.27-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.26-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.25-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.24-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.22-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.21-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.20-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.19-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.18-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.17-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.15-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.24-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.23-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.22-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.20-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.19-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Downloading langchain_openai-0.1.17-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.16-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.15-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.13-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Using cached langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.7-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.6-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.3-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading langchain_openai-0.0.2.post1-py3-none-any.whl.metadata (2.4 kB)\n",
      "  Downloading langchain_openai-0.0.2-py3-none-any.whl.metadata (570 bytes)\n",
      "Collecting langchain-community (from ragas)\n",
      "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain_community-0.4-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Downloading langchain_community-0.3.31-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langchain (from ragas)\n",
      "  Downloading langchain-1.2.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting requests>=2.32.2 (from datasets>=4.0.0->ragas)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain-community->ragas)\n",
      "  Using cached pydantic_settings-2.12.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "INFO: pip is looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain (from ragas)\n",
      "  Downloading langchain-1.2.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.2.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.3-py3-none-any.whl.metadata (4.9 kB)\n",
      "INFO: pip is still looking at multiple versions of langchain to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading langchain-1.1.2-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.1.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading langchain-1.0.6-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Downloading langchain-1.0.3-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain-1.0.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain-1.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Downloading langchain-1.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain->ragas)\n",
      "  Using cached langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langsmith<1.0.0,>=0.1.125 (from langchain-community->ragas)\n",
      "  Downloading langsmith-0.6.7-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core->ragas)\n",
      "  Downloading uuid_utils-0.14.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl.metadata (4.9 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.1.125->langchain-community->ragas)\n",
      "  Using cached zstandard-0.25.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->ragas)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from tiktoken->ragas) (2024.11.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from pandas->datasets>=4.0.0->ragas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from pandas->datasets>=4.0.0->ragas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from pandas->datasets>=4.0.0->ragas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/inflearn_langgraph/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=4.0.0->ragas) (1.17.0)\n",
      "Collecting scipy>=1.7.3 (from scikit-network->ragas)\n",
      "  Downloading scipy-1.17.0-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Downloading ragas-0.4.3-py3-none-any.whl (466 kB)\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading instructor-1.14.5-py3-none-any.whl (177 kB)\n",
      "Downloading docstring_parser-0.17.0-py3-none-any.whl (36 kB)\n",
      "Downloading openai-2.16.0-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0mm0:00:01\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.11.1-cp312-cp312-macosx_11_0_arm64.whl (315 kB)\n",
      "Downloading langchain_community-0.3.31-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m838.1 kB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_core-0.3.83-py3-none-any.whl (458 kB)\n",
      "Using cached langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n",
      "Downloading langsmith-0.6.7-py3-none-any.whl (309 kB)\n",
      "Using cached pydantic_settings-2.12.0-py3-none-any.whl (51 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading uuid_utils-0.14.0-cp39-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (601 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m601.8/601.8 kB\u001b[0m \u001b[31m865.7 kB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm-:--:--\u001b[0m\n",
      "\u001b[?25hUsing cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Using cached zstandard-0.25.0-cp312-cp312-macosx_11_0_arm64.whl (640 kB)\n",
      "Using cached networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "Downloading scikit_network-0.33.5-cp312-cp312-macosx_11_0_arm64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m928.6 kB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.17.0-cp312-cp312-macosx_14_0_arm64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m861.4 kB/s\u001b[0m  \u001b[33m0:00:23\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: appdirs, zstandard, uuid-utils, typing-inspection, scipy, requests, networkx, jiter, docstring-parser, diskcache, scikit-network, pydantic-settings, openai, langsmith, langchain-core, instructor, langchain-text-splitters, langchain_openai, langchain, langchain-community, ragas\n",
      "\u001b[2K  Attempting uninstall: requests0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/21\u001b[0m [scipy]\n",
      "\u001b[2K    Found existing installation: requests 2.32.3━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/21\u001b[0m [scipy]\n",
      "\u001b[2K    Uninstalling requests-2.32.3:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/21\u001b[0m [scipy]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.3━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/21\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: jiter\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: jiter 0.8.2━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling jiter-0.8.2:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled jiter-0.8.2━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/21\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: pydantic-settings\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K    Found existing installation: pydantic-settings 2.7.0━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K    Uninstalling pydantic-settings-2.7.0:m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K      Successfully uninstalled pydantic-settings-2.7.0━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K  Attempting uninstall: openai0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K    Found existing installation: openai 1.58.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K    Uninstalling openai-1.58.1:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K      Successfully uninstalled openai-1.58.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/21\u001b[0m [scikit-network]\n",
      "\u001b[2K  Attempting uninstall: langsmithm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/21\u001b[0m [openai]ork]\n",
      "\u001b[2K    Found existing installation: langsmith 0.2.6━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/21\u001b[0m [openai]\n",
      "\u001b[2K    Uninstalling langsmith-0.2.6:1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/21\u001b[0m [openai]\n",
      "\u001b[2K      Successfully uninstalled langsmith-0.2.6━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/21\u001b[0m [openai]\n",
      "\u001b[2K  Attempting uninstall: langchain-core91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/21\u001b[0m [langsmith]\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.28━━━━━━━━\u001b[0m \u001b[32m13/21\u001b[0m [langsmith]\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.28:[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/21\u001b[0m [langsmith]\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.28━━━━━━━━━━\u001b[0m \u001b[32m13/21\u001b[0m [langsmith]\n",
      "\u001b[2K  Attempting uninstall: langchain-text-splitters\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m14/21\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain-text-splitters 0.3.4[0m \u001b[32m14/21\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-text-splitters-0.3.4:m━━━━━━━━━━━━━\u001b[0m \u001b[32m14/21\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-text-splitters-0.3.4━\u001b[0m \u001b[32m14/21\u001b[0m [langchain-core]\n",
      "\u001b[2K  Attempting uninstall: langchain_openai0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K    Found existing installation: langchain-openai 0.2.14━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K    Uninstalling langchain-openai-0.2.14:0m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K      Successfully uninstalled langchain-openai-0.2.14━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K  Attempting uninstall: langchain━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.13[90m━━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K    Uninstalling langchain-0.3.13:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.13m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m16/21\u001b[0m [langchain-text-splitters]\n",
      "\u001b[2K  Attempting uninstall: langchain-community[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m18/21\u001b[0m [langchain]-splitters]\n",
      "\u001b[2K    Found existing installation: langchain-community 0.3.13━━━\u001b[0m \u001b[32m18/21\u001b[0m [langchain]\n",
      "\u001b[2K    Uninstalling langchain-community-0.3.13:90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m18/21\u001b[0m [langchain]\n",
      "\u001b[2K      Successfully uninstalled langchain-community-0.3.13━━━━━\u001b[0m \u001b[32m18/21\u001b[0m [langchain]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/21\u001b[0m [ragas]m20/21\u001b[0m [ragas]ain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed appdirs-1.4.4 diskcache-5.6.3 docstring-parser-0.17.0 instructor-1.14.5 jiter-0.11.1 langchain-0.3.27 langchain-community-0.3.31 langchain-core-0.3.83 langchain-text-splitters-0.3.11 langchain_openai-0.3.35 langsmith-0.6.7 networkx-3.6.1 openai-2.16.0 pydantic-settings-2.12.0 ragas-0.4.3 requests-2.32.5 scikit-network-0.33.5 scipy-1.17.0 typing-inspection-0.4.2 uuid-utils-0.14.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install datasets\n",
    "#!pip install ragas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954e635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn_langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
